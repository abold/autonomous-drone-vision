# ğŸ›¸ Autonomous Drone Vision â€“ Deep Learning Exploration

A deep learning experiment applying **YOLOv8** to aerial imagery from the **VisDrone 2019 dataset**, aiming to detect vehicles and pedestrians from drone footage.

---

## ğŸ¯ Objective
To develop a lightweight computer vision model capable of detecting and classifying common objects (e.g., *person*, *car*, *truck*, *bus*, *motorcycle*) in aerial drone scenes.  
The project demonstrates model training, data preparation, and evaluation â€” with skills transferable to automated risk analysis and quantitative modeling.

---

## ğŸ“¦ Dataset
**VisDrone 2019 DET**  
- ~14,000 annotated drone images  
- Converted to YOLO format with a custom script (`convert_visdrone_to_yolo.py`)  
- Split: 80% training / 20% validation  
- Classes:

---

## âš™ï¸ Environment
| Component | Details |
|:--|:--|
| Hardware | MacBook Pro (M4, 16 GB RAM) |
| OS | macOS |
| Framework | PyTorch + Ultralytics YOLOv8 |
| Acceleration | MPS (Apple GPU backend) |
| Python | 3.14 (venv) |

---

## ğŸš€ Training Configuration

| Parameter | Value |
|:--|:--|
| Model | YOLOv8n (pretrained) |
| Epochs | 50 |
| Image size | 512Ã—512 |
| Batch size | 4 |
| Device | MPS |

### ğŸ§  Training Command
yolo task=detect mode=train \
  model=yolov8n.pt \
  data=data/visdrone_yolo/data.yaml \
  epochs=50 imgsz=512 batch=4 device=mps \
  project=runs_drone_vision name=yolov8n_clean 

---

## ğŸ“Š Results Summary
| Metric | Score | Notes |
|:--|:--:|:--|
| mAP@50 | â‰ˆ 0.30 | Solid baseline for YOLOv8n |
| mAP@50-95 | â‰ˆ 0.18 | Consistent with aerial datasets |
| Precision | 0.55â€“0.70 | Stable |
| Recall | 0.25â€“0.30 | Gradually improving |

**Loss curves**  
<p align="center">
<img src="docs/results.png" width="80%">
</p>

**Confusion Matrix**
<p align="center">
<img src="docs/confusion_matrix.png" width="70%">
</p>

---

## ğŸ§  Insights
- Clean dataset structure and annotation consistency are crucial for YOLO training.  
- MPS backend on Apple Silicon performs well for small models.  
- Performance trade-off between model size (n, s, m) and precision.  
- The project provides a foundation for future work in **autonomous navigation** and **risk detection** systems.

---

## ğŸ”® Next Steps
- Retrain with `yolov8s.pt` and 100 epochs  
- Add augmentation (scale, hue, flip)  
- Build a **Gradio/Streamlit** demo for interactive inference  
- Integrate preview on [thinkboldwithanar.com](https://www.thinkboldwithanar.com)

---

## ğŸ“‚ Repository Structure
drone-vision/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ visdrone_yolo/
â”‚ â”‚ â”œâ”€â”€ images/
â”‚ â”‚ â””â”€â”€ labels/
â”œâ”€â”€ tools/
â”‚ â””â”€â”€ convert_visdrone_to_yolo.py
â”œâ”€â”€ runs_drone_vision/
â”œâ”€â”€ README.md
â””â”€â”€ yolov8n.pt

---

### ğŸ§© Author
**Anar Bold**  
ğŸ“ Zurich, Switzerland  
ğŸ“ MSc Physics (UZH) | Actuarial & Quantitative Analytics | AI/ML Enthusiast  
ğŸŒ [thinkboldwithanar.com](https://www.thinkboldwithanar.com)

---

### ğŸ·ï¸ License
This repository is for educational and research purposes only.  
Dataset Â© VisDrone 2019 authors. Model training and scripts Â© Anar Bold.

